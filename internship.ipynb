{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravallika89ch/alignn/blob/main/internship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhuftlj87jMe",
        "outputId": "e164f98f-d971-4e22-e436-a63f70c239e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfDm6Bh8O45E",
        "outputId": "6019a5c4-fedb-4db0-ad85-5d8d1c62f149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6yJDLfu7kbJK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X2tWj7UQi3Y",
        "outputId": "40a72951-80a5-41c7-b2b5-bdaaac17fcf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bfailed\n",
            "\n",
            "SpecsConfigurationConflictError: Requested specs conflict with configured specs.\n",
            "  requested specs: \n",
            "    - numpy=1.23.5\n",
            "    - pandas=1.5.3\n",
            "    - python=3.10\n",
            "  pinned specs: \n",
            "    - cuda-version=12\n",
            "    - python=3.11\n",
            "    - python_abi=3.11[build=*cp311*]\n",
            "Use 'conda config --show-sources' to look for 'pinned_specs' and 'track_features'\n",
            "configuration parameters.  Pinned specs may also be defined in the file\n",
            "/usr/local/conda-meta/pinned.\n",
            "\n",
            "\n",
            "Requirement already satisfied: jarvis-tools in /usr/local/lib/python3.11/site-packages (2025.5.30)\n",
            "Requirement already satisfied: alignn in /usr/local/lib/python3.11/site-packages (2025.4.1)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.11/site-packages (0.11.0)\n",
            "Requirement already satisfied: dgl==1.1.1 in /usr/local/lib/python3.11/site-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/site-packages (from dgl==1.1.1) (7.0.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/site-packages (from jarvis-tools) (3.10.3)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/site-packages (from jarvis-tools) (1.5.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/site-packages (from jarvis-tools) (1.0.0)\n",
            "Requirement already satisfied: xmltodict>=0.11.0 in /usr/local/lib/python3.11/site-packages (from jarvis-tools) (0.14.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (from jarvis-tools) (1.7.0)\n",
            "Requirement already satisfied: torch<=2.2.1 in /usr/local/lib/python3.11/site-packages (from alignn) (2.2.1)\n",
            "Requirement already satisfied: mpmath<=1.3.0 in /usr/local/lib/python3.11/site-packages (from alignn) (1.3.0)\n",
            "Requirement already satisfied: spglib>=2.0.2 in /usr/local/lib/python3.11/site-packages (from alignn) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.11/site-packages (from alignn) (2.3.0)\n",
            "Requirement already satisfied: pydantic>=1.8.1 in /usr/local/lib/python3.11/site-packages (from alignn) (2.11.7)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.11/site-packages (from alignn) (2.10.1)\n",
            "Requirement already satisfied: flake8>=3.9.1 in /usr/local/lib/python3.11/site-packages (from alignn) (7.3.0)\n",
            "Requirement already satisfied: pycodestyle>=2.7.0 in /usr/local/lib/python3.11/site-packages (from alignn) (2.14.0)\n",
            "Requirement already satisfied: pydocstyle>=6.0.0 in /usr/local/lib/python3.11/site-packages (from alignn) (6.3.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.2.1 in /usr/local/lib/python3.11/site-packages (from alignn) (2.4.7)\n",
            "Requirement already satisfied: ase in /usr/local/lib/python3.11/site-packages (from alignn) (3.25.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/site-packages (from alignn) (1.6.2)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/site-packages (from torchdata) (2.3.0)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from flake8>=3.9.1->alignn) (0.7.0)\n",
            "Requirement already satisfied: pyflakes<3.5.0,>=3.4.0 in /usr/local/lib/python3.11/site-packages (from flake8>=3.9.1->alignn) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib>=3.0.0->jarvis-tools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2.3->alignn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=1.2.3->alignn) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=1.8.1->alignn) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=1.8.1->alignn) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/site-packages (from pydantic>=1.8.1->alignn) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/site-packages (from pydantic>=1.8.1->alignn) (0.4.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2.0 in /usr/local/lib/python3.11/site-packages (from pydocstyle>=6.0.0->alignn) (3.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->dgl==1.1.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->dgl==1.1.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.19.0->dgl==1.1.1) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn->jarvis-tools) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/site-packages (from torch<=2.2.1->alignn) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.2.1->alignn) (12.9.86)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/site-packages (from pydantic-settings->alignn) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->jarvis-tools) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch<=2.2.1->alignn) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!conda install -y numpy=1.23.5 pandas=1.5.3 python=3.10\n",
        "!pip install jarvis-tools alignn torchdata dgl==1.1.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGMI6eL4Q4tq",
        "outputId": "d2781899-c6df-437e-e849-c954cfef53b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset JSON created: co2_dataset.json\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from jarvis.core.atoms import Atoms\n",
        "\n",
        "# Set your folder paths\n",
        "csv_path = \"/content/drive/MyDrive/Internship/tmdc-co2-meoh/dataset/opentmdc/co2.vaspfiles/id_prop.csv\"\n",
        "vasp_folder = \"/content/drive/MyDrive/Internship/tmdc-co2-meoh/dataset/opentmdc/co2.vaspfiles\"\n",
        "output_json = \"co2_dataset.json\"\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Prepare dataset list\n",
        "dataset = []\n",
        "for i, row in df.iterrows():\n",
        "    vasp_file = os.path.join(vasp_folder, row['id'])\n",
        "    atoms = Atoms.from_poscar(vasp_file)\n",
        "    dataset.append({\n",
        "        \"structure\": atoms.to_dict(),\n",
        "        \"target\": float(row['adsorption_energy (eV)']),\n",
        "        \"jid\": row['id']\n",
        "    })\n",
        "\n",
        "# Save JSON\n",
        "with open(output_json, \"w\") as f:\n",
        "    json.dump(dataset, f, indent=2)\n",
        "\n",
        "print(\"Dataset JSON created:\", output_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxrMOxDuSiDG",
        "outputId": "3e83b3b6-687f-412c-dbec-9b1be499c809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed file written as co2_dataset_fixed.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the original file\n",
        "with open(\"co2_dataset.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Fix structure ‚ûù atoms\n",
        "for entry in data:\n",
        "    entry[\"atoms\"] = entry.pop(\"structure\")\n",
        "\n",
        "# Save it back\n",
        "with open(\"co2_dataset_fixed.json\", \"w\") as f:\n",
        "    json.dump(data, f, indent=2)\n",
        "\n",
        "print(\"Fixed file written as co2_dataset_fixed.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrziv22ESoGz",
        "outputId": "2057f0e2-92a0-41ea-982b-37df88b62c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ train/val/test JSON files created.\n"
          ]
        }
      ],
      "source": [
        "import json, random\n",
        "\n",
        "with open(\"co2_dataset_fixed.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Shuffle for randomness\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split\n",
        "train, val, test = data[:30], data[30:33], data[33:36]\n",
        "\n",
        "# Save\n",
        "with open(\"train.json\", \"w\") as f: json.dump(train, f, indent=2)\n",
        "with open(\"val.json\", \"w\") as f: json.dump(val, f, indent=2)\n",
        "with open(\"test.json\", \"w\") as f: json.dump(test, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ train/val/test JSON files created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC31tvtmStY5",
        "outputId": "11450f5d-da20-4bfa-b216-b08925afba91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Total training samples: 30\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"train.json\", \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ Total training samples: {len(train_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZZABoobUrLJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"filename\": \"co2_dataset_fixed.json\",\n",
        "    \"dataset\": \"user_data\",\n",
        "    \"use_lmdb\": False,\n",
        "    \"target\": \"target\",\n",
        "    \"id_tag\": \"jid\",\n",
        "    \"atom_features\": \"cgcnn\",\n",
        "    \"neighbor_strategy\": \"k-nearest\",\n",
        "    \"dtype\": \"float32\",\n",
        "    \"random_seed\": 7,\n",
        "    \"n_train\": 27,\n",
        "    \"n_val\": 6,\n",
        "    \"n_test\": 3,  # total: 36\n",
        "    \"epochs\": 100,  # more chances for val improvement\n",
        "    \"batch_size\": 8,  # smaller batch = more updates\n",
        "    \"learning_rate\": 0.0003,  # slower learning for stability\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"warmup_steps\": 1000,\n",
        "    \"criterion\": \"mse\",\n",
        "    \"optimizer\": \"adamw\",\n",
        "    \"scheduler\": \"onecycle\",\n",
        "    \"n_early_stopping\": 10,  # stop if val loss stagnates\n",
        "    \"log_tensorboard\": False,\n",
        "    \"standard_scalar_and_pca\": True,  # normalize target values!\n",
        "    \"write_checkpoint\": True,\n",
        "    \"write_predictions\": True,\n",
        "    \"store_outputs\": True,\n",
        "    \"progress\": True,\n",
        "    \"compute_line_graph\": True,\n",
        "    \"cutoff\": 6.0,\n",
        "    \"cutoff_extra\": 2.0,\n",
        "    \"max_neighbors\": 12,\n",
        "    \"keep_data_order\": True,\n",
        "    \"model\": {\n",
        "        \"name\": \"alignn\",\n",
        "        \"alignn_layers\": 2,\n",
        "        \"gcn_layers\": 2,\n",
        "        \"atom_input_features\": 92,\n",
        "        \"edge_input_features\": 80,\n",
        "        \"triplet_input_features\": 40,\n",
        "        \"embedding_features\": 32,\n",
        "        \"hidden_features\": 128,\n",
        "        \"output_features\": 1,\n",
        "        \"link\": \"identity\",\n",
        "        \"zero_inflated\": False,\n",
        "        \"classification\": False,\n",
        "        \"num_classes\": 2,\n",
        "        \"extra_features\": 0\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "uGo-W1r5ldJT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uk9RX-dPbUv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909d66d0-503a-493e-fec1-c9050b3efb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Config saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"configfile.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Config saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n0koQAolUTJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af64ff0-3dfc-4bb2-a5f0-063bfeba3528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MPLBACKEND=Agg\n"
          ]
        }
      ],
      "source": [
        "%env MPLBACKEND=Agg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7STL6QgLVrCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0714377-6195-405e-a415-4cc63bb74a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'alignn' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/usnistgov/alignn.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k1xLs4zFbBlH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"co2_dataset_fixed.json\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"üì¶ Loaded {len(data)} entries\")\n",
        "print(\"üîë First record keys:\", data[0].keys() if data else \"Empty dataset\")\n"
      ],
      "metadata": {
        "id": "ecRSMARvoqm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcff25b-1924-4660-b69d-59837b9310de"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Loaded 36 entries\n",
            "üîë First record keys: dict_keys(['target', 'jid', 'atoms'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "O96-4uAzKqGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbe1fc7-d390-46d7-9111-a1c2498ce705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ alignn loaded from: /content/alignn/alignn/__init__.py\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/alignn/alignn/train.py:82: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  print(\"config:\", config.dict())\n",
            "config: {'version': 'NA', 'dataset': 'user_data', 'target': 'target', 'atom_features': 'cgcnn', 'neighbor_strategy': 'k-nearest', 'id_tag': 'jid', 'dtype': 'float32', 'random_seed': 7, 'classification_threshold': None, 'n_val': 6, 'n_test': 3, 'n_train': 27, 'train_ratio': 0.8, 'val_ratio': 0.1, 'test_ratio': 0.1, 'target_multiplication_factor': None, 'epochs': 100, 'batch_size': 8, 'weight_decay': 1e-05, 'learning_rate': 0.0003, 'filename': 'co2_dataset_fixed.json', 'warmup_steps': 1000, 'criterion': 'mse', 'optimizer': 'adamw', 'scheduler': 'onecycle', 'pin_memory': False, 'save_dataloader': False, 'write_checkpoint': True, 'write_predictions': True, 'store_outputs': True, 'progress': True, 'log_tensorboard': False, 'standard_scalar_and_pca': True, 'use_canonize': True, 'compute_line_graph': True, 'num_workers': 4, 'cutoff': 6.0, 'cutoff_extra': 2.0, 'max_neighbors': 12, 'keep_data_order': True, 'normalize_graph_level_loss': False, 'distributed': False, 'data_parallel': False, 'n_early_stopping': 10, 'output_dir': '/content', 'use_lmdb': False, 'model': {'name': 'alignn', 'alignn_layers': 2, 'gcn_layers': 2, 'atom_input_features': 92, 'edge_input_features': 80, 'triplet_input_features': 40, 'embedding_features': 32, 'hidden_features': 128, 'output_features': 1, 'link': 'identity', 'zero_inflated': False, 'classification': False, 'num_classes': 2, 'extra_features': 0}}\n",
            "/content/alignn/alignn/train.py:89: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  tmp = config.dict()\n",
            "{'atom_features': 'cgcnn',\n",
            " 'batch_size': 8,\n",
            " 'classification_threshold': None,\n",
            " 'compute_line_graph': True,\n",
            " 'criterion': 'mse',\n",
            " 'cutoff': 6.0,\n",
            " 'cutoff_extra': 2.0,\n",
            " 'data_parallel': False,\n",
            " 'dataset': 'user_data',\n",
            " 'distributed': False,\n",
            " 'dtype': 'float32',\n",
            " 'epochs': 100,\n",
            " 'filename': 'co2_dataset_fixed.json',\n",
            " 'id_tag': 'jid',\n",
            " 'keep_data_order': True,\n",
            " 'learning_rate': 0.0003,\n",
            " 'log_tensorboard': False,\n",
            " 'max_neighbors': 12,\n",
            " 'model': {'alignn_layers': 2,\n",
            "           'atom_input_features': 92,\n",
            "           'classification': False,\n",
            "           'edge_input_features': 80,\n",
            "           'embedding_features': 32,\n",
            "           'extra_features': 0,\n",
            "           'gcn_layers': 2,\n",
            "           'hidden_features': 128,\n",
            "           'link': 'identity',\n",
            "           'name': 'alignn',\n",
            "           'num_classes': 2,\n",
            "           'output_features': 1,\n",
            "           'triplet_input_features': 40,\n",
            "           'zero_inflated': False},\n",
            " 'n_early_stopping': 10,\n",
            " 'n_test': 3,\n",
            " 'n_train': 27,\n",
            " 'n_val': 6,\n",
            " 'neighbor_strategy': 'k-nearest',\n",
            " 'normalize_graph_level_loss': False,\n",
            " 'num_workers': 4,\n",
            " 'optimizer': 'adamw',\n",
            " 'output_dir': '/content',\n",
            " 'pin_memory': False,\n",
            " 'progress': True,\n",
            " 'random_seed': 7,\n",
            " 'save_dataloader': False,\n",
            " 'scheduler': 'onecycle',\n",
            " 'standard_scalar_and_pca': True,\n",
            " 'store_outputs': True,\n",
            " 'target': 'target',\n",
            " 'target_multiplication_factor': None,\n",
            " 'test_ratio': 0.1,\n",
            " 'train_ratio': 0.8,\n",
            " 'use_canonize': True,\n",
            " 'use_lmdb': False,\n",
            " 'val_ratio': 0.1,\n",
            " 'version': 'NA',\n",
            " 'warmup_steps': 1000,\n",
            " 'weight_decay': 1e-05,\n",
            " 'write_checkpoint': True,\n",
            " 'write_predictions': True}\n",
            "Not using LMDB dataset, memory footprint maybe high.\n",
            "WARNING: not using LMDB might result errors.\n",
            "üìÇ Loading user dataset from: co2_dataset_fixed.json\n",
            "Running StandardScalar\n",
            "Mean [0.43224288]\n",
            "Variance [8.94204441]\n",
            "New max [13.55181612]\n",
            "New min [-2.24996258]\n",
            "MAX val: 13.55181612\n",
            "MIN val: -2.24996258\n",
            "MAD: 1.3210392948148144\n",
            "Baseline MAE: 0.9727453325925927\n",
            "data range 13.55181612 -2.24996258\n",
            "Converting to graphs!\n",
            "100% 27/27 [00:03<00:00,  8.54it/s]\n",
            "df        target  ...                                              atoms\n",
            "0    1.279388  ...  {'lattice_mat': [[19.1418952942, 0.0, 0.0], [-...\n",
            "1   -0.134617  ...  {'lattice_mat': [[19.1418952942, 0.0, 0.0], [-...\n",
            "2   -0.084140  ...  {'lattice_mat': [[19.1418952942, 0.0, 0.0], [-...\n",
            "3   13.551816  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "4    0.106785  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "5   -0.015537  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "6    0.333258  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "7   -1.856544  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "8   -1.209472  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.52...\n",
            "9    1.686166  ...  {'lattice_mat': [[18.9192, 0.0, 1.2e-15], [-9....\n",
            "10  -0.065417  ...  {'lattice_mat': [[18.9192, 0.0, 1.2e-15], [-9....\n",
            "11  -0.003394  ...  {'lattice_mat': [[18.9192, 0.0, 1.2e-15], [-9....\n",
            "12  -0.102960  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "13  -0.003206  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "14   6.010615  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "15   0.066802  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "16  -2.249963  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "17  -1.655575  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 25.22...\n",
            "18   1.143370  ...  {'lattice_mat': [[19.734, 0.0, 1.2e-15], [-9.8...\n",
            "19  -0.228571  ...  {'lattice_mat': [[19.734, 0.0, 1.2e-15], [-9.8...\n",
            "20  -0.158909  ...  {'lattice_mat': [[19.734, 0.0, 1.2e-15], [-9.8...\n",
            "21  -0.242150  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "22  -0.040220  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "23  -1.057821  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "24   0.263179  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "25  -1.811266  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "26  -1.851059  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.31...\n",
            "\n",
            "[27 rows x 3 columns]\n",
            "/content/alignn/alignn/graphs.py:952: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  self.lattices = torch.tensor(self.lattices).type(\n",
            "warning: could not load CGCNN features for 103\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 101\n",
            "Setting it to max atomic number available here, 103\n",
            "warning: could not load CGCNN features for 102\n",
            "Setting it to max atomic number available here, 103\n",
            "building line graphs\n",
            "100% 27/27 [00:00<00:00, 163.18it/s]\n",
            "data range 1.25472419 -0.37772046\n",
            "Converting to graphs!\n",
            "100% 6/6 [00:00<00:00,  9.68it/s]\n",
            "df      target  ...                                              atoms\n",
            "0  1.254724  ...  {'lattice_mat': [[19.692, 0.0, 1.2e-15], [-9.8...\n",
            "1 -0.377720  ...  {'lattice_mat': [[19.692, 0.0, 1.2e-15], [-9.8...\n",
            "2 -0.296519  ...  {'lattice_mat': [[19.692, 0.0, 1.2e-15], [-9.8...\n",
            "3 -0.244683  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "4 -0.339104  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "5  0.966546  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "\n",
            "[6 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 6/6 [00:00<00:00, 200.23it/s]\n",
            "data range 0.01990308 -1.44422598\n",
            "Converting to graphs!\n",
            "100% 3/3 [00:00<00:00,  8.59it/s]\n",
            "df      target  ...                                              atoms\n",
            "0  0.019903  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "1 -0.197184  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "2 -1.444226  ...  {'lattice_mat': [[33.0, 0.0, 0.0], [0.0, 26.25...\n",
            "\n",
            "[3 rows x 3 columns]\n",
            "building line graphs\n",
            "100% 3/3 [00:00<00:00, 166.25it/s]\n",
            "/usr/local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "n_train: 27\n",
            "n_val  : 6\n",
            "n_test : 3\n",
            "\n",
            "    _    _     ___ ____ _   _ _   _\n",
            "   / \\  | |   |_ _/ ___| \\ | | \\ | |\n",
            "  / _ \\ | |    | | |  _|  \\| |  \\| |\n",
            " / ___ \\| |___ | | |_| | |\\  | |\\  |\n",
            "/_/   \\_\\_____|___\\____|_| \\_|_| \\_|\n",
            "\n",
            "Model parameters 523713\n",
            "CUDA available False\n",
            "CUDA device count 0\n",
            "‚ö†Ô∏è Warning: best_model is None ‚Äî training may have failed.\n"
          ]
        }
      ],
      "source": [
        "!python /content/alignn/alignn/train.py /content/configfile.json\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1diX8DjT0lQv5d_rISeQQQSHCcMDliqDD",
      "authorship_tag": "ABX9TyPW2HsFErkUmrxr7OsF62De",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}